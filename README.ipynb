{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CamTrapML\n",
    "\n",
    "> CamTrapML is a Python library for Detecting, Classifying, and Analysing Wildlife [Camera Trap](https://en.wikipedia.org/wiki/Camera_trap) Imagery.\n",
    "\n",
    "## Installation\n",
    "\n",
    "    $ pip install camtrapml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data\n",
    "\n",
    "Search for images in a directory, load an image and create a thumbnail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from camtrapml.dataset import Dataset\n",
    "from camtrapml.image.utils import load_image, thumbnail\n",
    "\n",
    "ena24 = Dataset(\n",
    "    name=\"ena24\",\n",
    "    path=\"~/Datasets/ena24/ena24\",\n",
    ")\n",
    "\n",
    "ena24_image_paths = list(ena24.enumerate_images())\n",
    "\n",
    "thumbnail(load_image(ena24_image_paths[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXIF Extraction\n",
    "\n",
    "EXIF extraction is a common task in gathering the metadata such as each image's timestamp, camera model, focal length, etc. Some researchers write labelling into the EXIF data. CamTrapML doesn't assist with writing to EXIF. However, there is functionality for extracting it for analysis and building datasets for training new models from previously labelled images.\n",
    "\n",
    "ExifTool is required for this package to work. Installation instructions can be found [here](https://exiftool.org/install.html).\n",
    "\n",
    "Three methods are available for extracting EXIF data from images. Each with different performance characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 1: Individual Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camtrapml.image.exif import extract_exif\n",
    "\n",
    "exif = extract_exif(ena24_image_paths[0])\n",
    "exif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 2: Multiple Images**\n",
    "\n",
    "`extract_multiple_exif` passes a list of image paths to ExifTool and returns a list of dictionaries containing the EXIF data. This is faster than `extract_exif` when multiple images are being processed as it only passes the list of image paths to ExifTool once, rather than spawning a new process for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camtrapml.image.exif import extract_multiple_exif\n",
    "\n",
    "exif = extract_multiple_exif(ena24_image_paths)\n",
    "exif[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 3: Multiple Images, Multiple Processes**\n",
    "\n",
    "When processing large datasets, it's apparent that the bottleneck in extracting the EXIF information tends to be the CPU. This method spawns multiple versions of ExifTool in parallel, each with a batch of image paths. This is faster than `extract_multiple_exif` when processing large datasets as it allows for multiple processes to be spawned and the data extracted in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camtrapml.image.exif import extract_multiple_exif_fast\n",
    "\n",
    "exif = extract_multiple_exif_fast(ena24_image_paths)\n",
    "exif[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection\n",
    "\n",
    "Various Detection models are available in the `camtrapml.detection` subpackage. These currently include MegaDetector (v4.1, v3 and v2) and support for loading in custom Tensorflow v1.x Object Detection Frozen models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detection with MegaDetector v4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camtrapml.detection.models.megadetector import MegaDetectorV4_1\n",
    "from camtrapml.detection.utils import render_detections\n",
    "\n",
    "with MegaDetectorV4_1() as detector:\n",
    "    detections = detector.detect(ena24_image_paths[0])\n",
    "\n",
    "thumbnail(\n",
    "    render_detections(ena24_image_paths[0], detections, class_map=detector.class_map)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detection with a custom Tensorflow v1.x Object Detection Frozen model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camtrapml.detection.models.tensorflow import TF1ODAPIFrozenModel\n",
    "from camtrapml.detection.utils import render_detections\n",
    "from pathlib import Path\n",
    "\n",
    "with TF1ODAPIFrozenModel(\n",
    "    model_path=Path(\"~/Downloads/my-custom-model.pb\").expanduser(),\n",
    "    model_image_tensor_name=\"image_tensor:0\",\n",
    "    model_boxes_tensor_name=\"detection_boxes:0\",\n",
    "    model_scores_tensor_name=\"detection_scores:0\",\n",
    "    model_classes_tensor_name=\"detection_classes:0\",\n",
    "    class_map={\n",
    "        1: \"animal\",\n",
    "    },\n",
    ") as detector:\n",
    "    detections = detector.detect(ena24_image_paths[1])\n",
    "\n",
    "thumbnail(\n",
    "    render_detections(ena24_image_paths[1], detections, class_map=detector.class_map)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camtrapml.detection.models.megadetector import MegaDetectorV4_1\n",
    "from camtrapml.detection.utils import extract_detections_from_image\n",
    "\n",
    "with MegaDetectorV4_1() as detector:\n",
    "    detections = detector.detect(ena24_image_paths[0])\n",
    "\n",
    "list(extract_detections_from_image(load_image(ena24_image_paths[0]), detections))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Humans from Images\n",
    "\n",
    "In order to reduce the risks of identification of humans in line with GDPR, CamTrapML provides the ability to remove humans from images. This is achieved by using the MegaDetector v3+ models to detect humans in the image, and then replacing all pixels in each human detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camtrapml.detection.models.megadetector import MegaDetectorV4_1\n",
    "from camtrapml.detection.utils import remove_detections_from_image\n",
    "from camtrapml.image.utils import load_image, thumbnail\n",
    "from pathlib import Path\n",
    "\n",
    "ct_image_with_humans = Path(\"~/Datasets/FieldDayDS/FieldDay/IMG_0576.JPG\").expanduser()\n",
    "\n",
    "with MegaDetectorV4_1() as detector:\n",
    "    detections = detector.detect(ct_image_with_humans)\n",
    "\n",
    "human_class_id = 2\n",
    "\n",
    "thumbnail(\n",
    "    remove_detections_from_image(\n",
    "        load_image(ct_image_with_humans),\n",
    "        [\n",
    "            detection\n",
    "            for detection in detections\n",
    "            if detection[\"category\"] == human_class_id and detection[\"conf\"] > 0.5\n",
    "        ],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding / Feature Vector Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camtrapml.detection.models.megadetector import read_megadetector_batch_file\n",
    "from camtrapml.image.utils import load_image\n",
    "from camtrapml.detection.utils import extract_detections_from_image\n",
    "from camtrapml.embedding.models.inaturalist import Inat2017InceptionV3\n",
    "from camtrapml.embedding.utils import plot_embeddings\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "image_paths, detections = read_megadetector_batch_file(\n",
    "    Path(\"~/Datasets/ENA24/ena24/md.4.1.0.json\").expanduser(),\n",
    "    image_dir=Path(\"~/Datasets/ENA24/ena24/\").expanduser(),\n",
    ")\n",
    "\n",
    "all_embeddings = []\n",
    "\n",
    "with Inat2017InceptionV3() as embeddings_model:\n",
    "    for (image_path, detections) in tqdm(list(zip(image_paths, detections))):\n",
    "        image = load_image(image_path)\n",
    "\n",
    "        detection_extracts = extract_detections_from_image(\n",
    "            image,\n",
    "            [\n",
    "                detection\n",
    "                for detection in detections\n",
    "                if detection[\"category\"] == \"1\" and detection[\"conf\"] > 0.5\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        for extract in detection_extracts:\n",
    "            all_embeddings.append(embeddings_model.predict(extract))\n",
    "\n",
    "plot_embeddings(np.array(all_embeddings))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52ee2977380704a66854748a73250e0671a9318bd5b3fd45a3df9f851ae61629"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
